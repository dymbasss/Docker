upstream application {
    # Алгоритм работает следующим образом: высчитывает хэш у адреса клиента и адреса сервера, 
    # и использует этот результат как уникальный ключ при балансировке.
    # ip_hash;
    # Алгоритм Least Connection обеспечивает равномерное распределение нагрузки между экземплярами 
    # приложения, как раз основываясь на количестве соединений с сервером.
    least_conn;
    server 172.18.0.96:3501;
    server 172.18.0.97:3502;
}

# --- Безопастность (прописать в nginx.conf) если используешь --- 
#limit_conn_zone $binary_remote_addr zone=addr:10m;
#limit_req_zone $binary_remote_addr zone=req_limit_per_ip:10m rate=10r/s;

server {
    # --- Общие настройки ---
    # Когда приходит http-запрос — nginx вначале сопоставляет ip-адрес и порт запроса 
    # с директивами listen в секциях server. Затем сопоставляет значение поле Host заголовка 
    # запроса с директивами server_name в секциях server, которые соответствуют ip-адресу и порту. 
    # Если имя сервера не найдено, запрос будет обработан сервером по умолчанию.
    listen 8080 ssl;
    listen 8081;
    #server example.com

    # --- Конфигурация с беком ---
    # Когда Nginx действует как обратный прокси-сервер, 
    # он перенаправляет запросы клиентов на внутренние 
    # серверы и получает ответы от их имени. Директива 
    # proxy_read_* будет ставить время ожидания на разных уровнях взаимодействия
    proxy_connect_timeout 75;
    proxy_send_timeout 60;
    proxy_read_timeout 60;

    # --- TLS / SSL шифрование ---
    ssl_certificate /usr/src/cert.pem;
    ssl_certificate_key /usr/src/key.pem;
    # На каждое соединение клиенту отдаётся уникальный идентификатор, 
    # а на сервере по данному идентификатору сохраняется сессионный ключ.
    # В приведённом примере настраивается зона разделяемой памяти с именем SSL 
    # размером 10 мегабайт (10 мегабайт). Размер можно настроить под требования сервера.
    ssl_session_cache shared:SSL:20m;
    # Задает время, в течение которого клиент может повторно использовать параметры сессии.
    ssl_session_timeout 10m;
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;

    # --- Безопастность (нужно подключать внешние модули см. выше)---
    # Конфигурация ограничивает количество 
    # соединений до 15 на каждый уникальный IP-адрес
    #limit_conn conn_limit_per_ip 15;
    # ---
    # Ограничивает частоту запросов до 10 в секунду (rate=10r/s ) на один IP-адрес
    # rate=10r/s — параметр, который устанавливает ограничение на количество запросов за определенный отрезок времени. 
    # Rate задает максимальное количество запросов. В примере выставлено десять запросов в секунду. 
    # Поддерживаются секунды (s) и минуты (m);
    # burst=5 — параметр, отвечающий за максимально разрешенный всплеск запросов. 
    # Например, если за 1 секунду с IP-адреса пришло 5     
    # запросов, то в следующую секунду не будет обработано ни одного запроса, 
    # пока не вернется число запросов в секунду в нормальный лимит. Параметр 
    # burst отвечает именно за количество запросов, а не за их скорость.
    # nodelay — параметр, отвечающий за то, что запросы, которые превысили разрешенный лимит, будут отклонены.
    #limit_req zone=req_limit_per_ip burst=5 nodelay;
    # ---

    # --- Логи ---
    access_log /usr/src/nginx/logs/nginx_access.log;
    error_log /usr/src/nginx/logs/nginx_error.log;
 
    location / {
        
        # блокировка на уровне ip
        #allow 172.17.0.1/24;
        #allow 172.17.0.1;
        #deny all;

        # Вначале нужно поменять схему и протокол в запросе, если у вас backend сервер работает 
        # на одном протоколе (например http), а к proxy подключаются по другому протоколу 
        # (например https). То-есть в заголовках X-Scheme и X-Forwarded-Proto нужно указать 
        # протокол подключения к backend серверу.
        proxy_set_header X-Scheme http;
        proxy_set_header X-Forwarded-Proto http;
        
        # $http_host — это то что указано в адресной строке вместе с портом, если он указан 
        # в адресной строке. Это работает только если порт не стандартный, например 8080. В нашем случае это proxy;
        # $host — это имя прокси сервера. Оно записано в /etc/nginx/sites-available/proxy, 
        # в параметре server_name. В нашем случае proxy;
        # $proxy_host — это имя backend сервер на который мы проксируем.
        proxy_set_header Host $http_host;
        
        # Заголовок X-Forwarded-For содержит список прокси серверов по которым прошёлся клиент 
        # перед этим сервером, а переменная $proxy_add_x_forwarded_for содержит полученный 
        # заголовок X-Forwarder-For плюс добавляет свой сервер в этот список (это используется 
        # для передачи реального ip-клиента на backend).
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # Эти заголовки содержать содержат ip адрес и порт с которого подключается клиент. 
        # Чтобы передать эти значения backend серверу, мы указали следующие параметры:
        proxy_set_header X-Real-PORT $remote_port;
        proxy_set_header X-Real-IP $remote_addr;
        
        # proxy_buffering — позволяет включить или отключить буферную память для прокси сервера;
        # proxy_buffer_size — размер буфера для первой части ответа получаемого от 
        # проксируемого сервера, такая часть ответа включает в себя только заголовки 
        # и хранится отдельно от остальной информации;
        # proxy_buffers — число и размер буферов для одного соединения, а вот сюда 
        # помещается ответ от проксируемого сервера.
        proxy_buffering on;
        proxy_buffer_size 8k;
        proxy_buffers 8 8k;
        proxy_pass http://application;
    }
}
